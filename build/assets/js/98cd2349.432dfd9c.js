"use strict";(globalThis.webpackChunkqwen=globalThis.webpackChunkqwen||[]).push([[469],{8453(n,e,i){i.d(e,{R:()=>r,x:()=>t});var l=i(6540);const s={},o=l.createContext(s);function r(n){const e=l.useContext(o);return l.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),l.createElement(o.Provider,{value:e},n.children)}},8612(n,e,i){i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>c});const l=JSON.parse('{"id":"modules/ai-robot-brain","title":"AI-Robot Brain","description":"The AI-Robot Brain module handles perception, navigation, and learning for the Autonomous Humanoid Robot System using NVIDIA Isaac technologies.","source":"@site/docs/modules/ai-robot-brain.md","sourceDirName":"modules","slug":"/modules/ai-robot-brain","permalink":"/robot-system/docs/modules/ai-robot-brain","draft":false,"unlisted":false,"editUrl":"https://github.com/qwen/robot-system/tree/main/docs/docs/modules/ai-robot-brain.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Digital Twin","permalink":"/robot-system/docs/modules/digital-twin"},"next":{"title":"Vision-Language-Action (VLA) Module","permalink":"/robot-system/docs/modules/vla-module"}}');var s=i(4848),o=i(8453);const r={},t="AI-Robot Brain",a={},c=[{value:"Overview",id:"overview",level:2},{value:"Components",id:"components",level:2},{value:"Perception System",id:"perception-system",level:3},{value:"Object Detection",id:"object-detection",level:4},{value:"Environment Modeling",id:"environment-modeling",level:4},{value:"Navigation System",id:"navigation-system",level:3},{value:"Global Planner",id:"global-planner",level:4},{value:"Local Planner",id:"local-planner",level:4},{value:"NVIDIA Isaac Integration",id:"nvidia-isaac-integration",level:2},{value:"Launch Files",id:"launch-files",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Topics and Services",id:"topics-and-services",level:2},{value:"Published Topics",id:"published-topics",level:3},{value:"Subscribed Topics",id:"subscribed-topics",level:3},{value:"Services",id:"services",level:3},{value:"Training",id:"training",level:2},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"ai-robot-brain",children:"AI-Robot Brain"})}),"\n",(0,s.jsx)(e.p,{children:"The AI-Robot Brain module handles perception, navigation, and learning for the Autonomous Humanoid Robot System using NVIDIA Isaac technologies."}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(e.p,{children:"The AI-Robot Brain is responsible for:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Environmental perception and understanding"}),"\n",(0,s.jsx)(e.li,{children:"Path planning and navigation"}),"\n",(0,s.jsx)(e.li,{children:"Object detection and recognition"}),"\n",(0,s.jsx)(e.li,{children:"Learning from experience"}),"\n",(0,s.jsx)(e.li,{children:"Decision making"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"components",children:"Components"}),"\n",(0,s.jsx)(e.h3,{id:"perception-system",children:"Perception System"}),"\n",(0,s.jsx)(e.p,{children:"The perception system processes sensory input to understand the environment:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class PerceptionNode(Node):\n    def __init__(self):\n        super().__init__('perception_node')\n        # Object detection, environment modeling, sensor fusion\n"})}),"\n",(0,s.jsx)(e.h4,{id:"object-detection",children:"Object Detection"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Real-time object recognition"}),"\n",(0,s.jsx)(e.li,{children:"3D object pose estimation"}),"\n",(0,s.jsx)(e.li,{children:"Semantic segmentation"}),"\n",(0,s.jsx)(e.li,{children:"Instance segmentation"}),"\n"]}),"\n",(0,s.jsx)(e.h4,{id:"environment-modeling",children:"Environment Modeling"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"3D mapping of the environment"}),"\n",(0,s.jsx)(e.li,{children:"Occupancy grid generation"}),"\n",(0,s.jsx)(e.li,{children:"Semantic mapping"}),"\n",(0,s.jsx)(e.li,{children:"Dynamic object tracking"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"navigation-system",children:"Navigation System"}),"\n",(0,s.jsx)(e.p,{children:"The navigation system handles path planning and obstacle avoidance:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class NavigationNode(Node):\n    def __init__(self):\n        super().__init__('navigation_node')\n        # Global and local planners, obstacle avoidance\n"})}),"\n",(0,s.jsx)(e.h4,{id:"global-planner",children:"Global Planner"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Path planning from start to goal"}),"\n",(0,s.jsx)(e.li,{children:"A* or Dijkstra's algorithm"}),"\n",(0,s.jsx)(e.li,{children:"Costmap-based planning"}),"\n",(0,s.jsx)(e.li,{children:"Dynamic reconfiguration"}),"\n"]}),"\n",(0,s.jsx)(e.h4,{id:"local-planner",children:"Local Planner"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Obstacle avoidance"}),"\n",(0,s.jsx)(e.li,{children:"Dynamic path adjustment"}),"\n",(0,s.jsx)(e.li,{children:"Velocity control"}),"\n",(0,s.jsx)(e.li,{children:"Collision prevention"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"nvidia-isaac-integration",children:"NVIDIA Isaac Integration"}),"\n",(0,s.jsx)(e.p,{children:"The system leverages NVIDIA Isaac technologies:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Isaac ROS for perception and navigation"}),"\n",(0,s.jsx)(e.li,{children:"GPU acceleration for deep learning"}),"\n",(0,s.jsx)(e.li,{children:"Hardware optimization"}),"\n",(0,s.jsx)(e.li,{children:"Pre-trained models"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"launch-files",children:"Launch Files"}),"\n",(0,s.jsx)(e.p,{children:"The AI-Robot Brain can be launched using:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 launch ai_robot_brain perception_nav.launch.py\n"})}),"\n",(0,s.jsx)(e.h2,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsx)(e.p,{children:"The AI-Robot Brain can be configured through:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"config/perception.yaml"})," - Perception parameters"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"config/navigation.yaml"})," - Navigation parameters"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"config/models/"})," - AI model configurations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"config/training/"})," - Training parameters"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"topics-and-services",children:"Topics and Services"}),"\n",(0,s.jsx)(e.h3,{id:"published-topics",children:"Published Topics"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/perception_results"})," - Processed perception data"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/navigation_path"})," - Planned navigation path"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/obstacle_map"})," - Detected obstacles"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/robot_map"})," - Environment map"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"subscribed-topics",children:"Subscribed Topics"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/sensor_data"})," - Raw sensor data from nervous system"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/user_command"})," - Commands from VLA module"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/robot_pose"})," - Current robot pose"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"services",children:"Services"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/plan_path"})," - Service to plan a path to a goal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/detect_objects"})," - Service to detect objects in the environment"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"/get_map"})," - Service to retrieve the environment map"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"training",children:"Training"}),"\n",(0,s.jsx)(e.p,{children:"The AI-Robot Brain includes capabilities for learning and improvement:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Reinforcement learning for navigation"}),"\n",(0,s.jsx)(e.li,{children:"Transfer learning for object detection"}),"\n",(0,s.jsx)(e.li,{children:"Online learning from experience"}),"\n",(0,s.jsx)(e.li,{children:"Simulation-to-real transfer"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"GPU acceleration for deep learning"}),"\n",(0,s.jsx)(e.li,{children:"Multi-threaded processing"}),"\n",(0,s.jsx)(e.li,{children:"Efficient data structures"}),"\n",(0,s.jsx)(e.li,{children:"Real-time constraints"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"If object detection is slow, check GPU utilization"}),"\n",(0,s.jsx)(e.li,{children:"If navigation fails, verify sensor data quality"}),"\n",(0,s.jsx)(e.li,{children:"If maps are inconsistent, check sensor calibration"}),"\n",(0,s.jsx)(e.li,{children:"If planning is erratic, adjust costmap parameters"}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);